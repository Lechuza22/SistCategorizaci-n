# ğŸ§± LLM Categorizer Demo

Este proyecto es una **demo funcional** de un sistema inteligente que procesa preguntas de usuarios, **las categoriza automÃ¡ticamente**, **busca documentos relevantes** y **genera respuestas** usando un modelo de lenguaje como GPT-4.

Fue desarrollado como **proyecto personal** y sirve como referencia para soluciones conversacionales en sectores como construcciÃ³n, educaciÃ³n, soporte tÃ©cnico, entre otros.

---

## ğŸš€ Â¿QuÃ© hace esta aplicaciÃ³n?

1. Carga documentos en texto o PDF.
2. Fragmenta y vectoriza el contenido usando **FAISS** y **OpenAI embeddings**.
3. Acepta preguntas de usuarios.
4. Recupera los fragmentos mÃ¡s relevantes con bÃºsqueda semÃ¡ntica.
5. Construye un prompt con contexto y lo envÃ­a al **LLM (GPT-4)**.
6. Devuelve una respuesta clara y contextualizada al usuario.

---

## ğŸ§° TecnologÃ­as utilizadas

- [Python](https://www.python.org/)
- [Streamlit](https://streamlit.io/)
- [LangChain](https://www.langchain.com/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [OpenAI API](https://platform.openai.com/)
- [dotenv](https://pypi.org/project/python-dotenv/)

---

## ğŸ“ Estructura del proyecto

```
llm-categorizer-demo/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Interfaz Streamlit
â”‚   â”œâ”€â”€ config.py              # Clave API
â”‚   â”œâ”€â”€ generate_embeddings.py # Carga y vectorizaciÃ³n de documentos
â”‚   â”œâ”€â”€ search_documents.py    # BÃºsqueda semÃ¡ntica con FAISS
â”‚   â””â”€â”€ generate_response.py   # GeneraciÃ³n de respuesta con GPT
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documentos_raw/        # Tus archivos .txt o .pdf
â”œâ”€â”€ vectorstore/               # Ãndice FAISS generado
â”œâ”€â”€ .env                       # Clave API privada
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ InstalaciÃ³n y ejecuciÃ³n

### 1. ClonÃ¡ el repositorio

```bash
git clone https://github.com/tu-usuario/llm-categorizer-demo.git
cd llm-categorizer-demo
```

### 2. InstalÃ¡ dependencias

```bash
pip install -r requirements.txt
```

### 3. ConfigurÃ¡ la clave de OpenAI

Crea un archivo `.env` en la raÃ­z con:

```env
OPENAI_API_KEY=sk-tu-clave-aqui
```

### 4. ColocÃ¡ documentos en la carpeta

```bash
/data/documentos_raw/
```

PodÃ©s usar `.txt` o `.pdf`.

### 5. GenerÃ¡ los embeddings

```bash
python app/generate_embeddings.py
```

### 6. EjecutÃ¡ la aplicaciÃ³n

```bash
streamlit run app/main.py
```

---

## ğŸ§ª Ejemplo de uso

1. SubÃ­ un archivo `.txt` con contenido tÃ©cnico.
2. HacÃ© una consulta desde la interfaz.
3. El sistema buscarÃ¡ los fragmentos mÃ¡s relevantes.
4. El modelo generarÃ¡ una respuesta basada en los documentos.

---

## ğŸ§  Casos de uso

- Chatbots internos basados en documentaciÃ³n de empresa
- Asistentes tÃ©cnicos entrenados con manuales
- Sistemas de ayuda en sectores como:
  - ConstrucciÃ³n
  - EducaciÃ³n
  - Soporte de software

---

## ğŸ“Œ CrÃ©ditos

Desarrollado por [JerÃ³nimo MartÃ­nez](https://www.linkedin.com/in/jeronimo-martinez/), Data Scientist especializado en soluciones aplicadas con IA.


## ğŸŒ DEMO en Vivo

ProbÃ¡ la aplicaciÃ³n funcionando en:

ğŸ‘‰ [Streamlit Cloud](https://llm-categorizer-demo.streamlit.app)
