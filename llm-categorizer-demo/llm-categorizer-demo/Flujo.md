# ðŸ§© Resumen del Proyecto
Objetivo: Procesar consultas externas, categorizarlas, buscar documentos relevantes y generar respuestas usando un LLM (como GPT o Claude).
Stack sugerido:

Backend: Python + LangChain o LlamaIndex

Frontend: Streamlit / React

LLM: OpenAI (GPT-4o), Claude, o Amazon Bedrock

Vector DB: FAISS (local) o Pinecone (cloud)

Infraestructura: AWS (Lambda, S3, API Gateway, IAM)

## ðŸš€ Fases del Proyecto
ðŸŸ¦ FASE 1 â€“ DiseÃ±o y Setup Inicial
DiseÃ±o conceptual (listo)

SolicitÃ¡ recursos en Jira (criterios 2, 3 y 4):

Nuevo repo GitHub

Acceso a deploy AWS (Lambda, S3, API Gateway)

Dependencias necesarias (APIs, SDKs, claves, embeddings)

Estructura del repositorio

bash
Copiar
Editar
llm-query-flow/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py         # endpoint o interfaz Streamlit
â”‚   â”œâ”€â”€ categorize.py   # categorizaciÃ³n
â”‚   â”œâ”€â”€ search_docs.py  # bÃºsqueda en base de documentos
â”‚   â””â”€â”€ generate_answer.py  # integraciÃ³n con el LLM
â”œâ”€â”€ data/               # documentos cargados
â”œâ”€â”€ vector_store/       # FAISS u otro motor
â””â”€â”€ requirements.txt
## ðŸŸ¨ FASE 2 â€“ Desarrollo del Backend
Carga y preprocesamiento de documentos

Extraer texto, dividir en chunks, limpiar y almacenar en data/.

Usar embeddings (OpenAIEmbeddings, HuggingFaceEmbeddings, etc.)

Guardar Ã­ndices en FAISS.

CategorizaciÃ³n

Implementar modelo de clasificaciÃ³n (modelo entrenado o reglas).

Ej: Prompt + LLM â†’ "Â¿Esta pregunta se refiere a materiales, logÃ­stica, preciosâ€¦?"

BÃºsqueda semÃ¡ntica

Usar embeddings + FAISS para recuperar los documentos mÃ¡s similares.

Fallback si no hay documentos relevantes: usar solo LLM.

GeneraciÃ³n de respuesta

Armar prompt del tipo:

txt
Copiar
Editar
Contexto: [Fragmento1] [Fragmento2] [Fragmento3]
Pregunta: Â¿QuÃ© tipo de cemento se recomienda para techos?
Respuesta:
Enviarlo al LLM y mostrar resultado.

## ðŸŸ© FASE 3 â€“ Frontend y Demo
AutenticaciÃ³n por whitelist

Validar que el usuario (Customer A o B) estÃ© habilitado.

Interfaz (Streamlit o React)

Campo de texto para pregunta

Filtros: categorÃ­a y subcategorÃ­a (opcional)

Respuesta generada

VisualizaciÃ³n de los documentos usados (transparencia)

Dashboard demo

URL: softwarefactoryai.com/chat/demo

Mostrar categorÃ­as + interacciÃ³n con preguntas reales

## ðŸŸ¥ FASE 4 â€“ Testing y ValidaciÃ³n
Implementar y probar los 5 escenarios de prueba:

Pregunta relevante

Sin documentos relevantes

Fuera de Ã¡mbito

Pregunta ambigua

Pregunta que requiere detalle exacto

Checklist de criterios de aceptaciÃ³n:

Validar que cada escenario tenga lÃ³gica, fallback y respuesta adecuada.

## ðŸŸ¦ FASE 5 â€“ Deploy en AWS
Infraestructura mÃ­nima en AWS:

API Gateway + Lambda (si es backend puro)

S3 (para los documentos y configuraciÃ³n)

IAM para permisos

(opcional) ECS o EC2 si usÃ¡s FAISS con gran volumen

CI/CD con GitHub Actions

Testeo + deploy automÃ¡tico al hacer push en main

