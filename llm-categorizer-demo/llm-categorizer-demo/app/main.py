# app/main.py

import streamlit as st
from app.search_documents import buscar_documentos_relevantes
from app.generate_response import generar_respuesta_con_llm

st.set_page_config(page_title="ğŸ§  LLM Categorizer Demo", layout="centered")

st.title("ğŸ§± LLM Categorizer Demo")
st.write("Esta demo utiliza el modelo Gemini Pro para generar respuestas basadas en documentos.")

pregunta = st.text_input("ğŸ” IngresÃ¡ tu consulta:")

if pregunta:
    with st.spinner("ğŸ” Buscando documentos relevantes..."):
        fragmentos = buscar_documentos_relevantes(pregunta)

    st.subheader("ğŸ“„ Fragmentos relevantes encontrados:")
    for i, doc in enumerate(fragmentos, 1):
        st.markdown(f"**Fragmento #{i}:**")
        st.info(doc.page_content)

    with st.spinner("âœï¸ Generando respuesta con Gemini..."):
        respuesta = generar_respuesta_con_llm(pregunta, fragmentos, modelo="gemini")

    st.subheader("ğŸ“Œ Respuesta generada:")
    st.success(respuesta)